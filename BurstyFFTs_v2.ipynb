{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "following-drain",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import scipy as sp"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "younger-visitor",
   "metadata": {},
   "source": [
    "# Theory\n",
    "\n",
    "We seek to find the FFT of a bursty signal that begins at times $x(t_0), x(t_1) ...$ and lasts for $t_L$ seconds.\n",
    "The most obvious way to perform this is to capture all the bursts in one window and perform a single FFT.\n",
    "However, this can be very inefficient if the gap between each burst is very large i.e. $t_0 + t_L << t_1, t_1 + t_L << t_2 ...$. In such a scenario, zeroing out the empty space between each burst is commonplace and will result in the FFT being needlessly computed over all the '0' samples.\n",
    "\n",
    "Instead, we would like to perform the FFT over each short burst and then combine them such that the result for a particular bin would be the same as if the FFT had been taken over all the bursts together.\n",
    "\n",
    "To do this, consider the standard form of the FFT:\n",
    "\n",
    "$$X(k) = \\sum^{N-1}_{n} x(n) e^{-i 2 \\pi k n / N}, k = 0, 1, ... N-1 $$\n",
    "\n",
    "Now, before considering the bursts, instead break this large FFT into a bunch of smaller FFTs of length L. In practice this length would be determined by a desired bin resolution, and by zero-padding the original long window, we may define\n",
    "\n",
    "$$ N = \\alpha L$$\n",
    "\n",
    "where $\\alpha$ is an integer. This is not a new technique and is simply performing stacked FFTs in a overlap-add manner. We can see this by simply splitting the above summation into smaller summations over L terms.\n",
    "\n",
    "$$\n",
    "\\begin{aligned}\n",
    "X(k) &= \\sum^{L-1}_{n=0} x(n) e^{-i 2 \\pi k n / N} + \\sum^{2L-1}_{n=L} x(n) e^{-i 2 \\pi k n / N} + ... \\\\\n",
    "&= \\sum^{L-1}_{n=0} x(n) e^{-i 2 \\pi k n / (\\alpha L)} + \\sum^{2L-1}_{n=L} x(n) e^{-i 2 \\pi k n / (\\alpha L)} + ... \\\\\n",
    "&= \\sum^{L-1}_{n=0} x(n) e^{-i 2 \\pi k' n / L)} + \\sum^{2L-1}_{n=L} x(n) e^{-i 2 \\pi k' n / L} + ..., \\; k' = k/\\alpha \\\\\n",
    "\\end{aligned}\n",
    "$$\n",
    "\n",
    "We see that we can define $k' = 0, 1, ..., L-1$ which continues from our definition of $N=\\alpha L$. In other words, we have split the long FFT into the sum of smaller FFTs, with a corresponding loss of bin resolution of factor $\\alpha$. We can make this clearer by labelling the windows in the following way (now using $k'$ as the bin number):\n",
    "\n",
    "$$\n",
    "\\begin{aligned}\n",
    "X(k') &= \\sum^{L-1}_{n=0} x(n+0L) e^{-i 2 \\pi k' (n + 0L) / L)} + \\sum^{L-1}_{n=0} x(n+1L) e^{-i 2 \\pi k' (n+1L) / L} + ... \\\\\n",
    "&= (\\sum^{L-1}_{n=0} x(n+0L) e^{-i 2 \\pi k' n/L}) e^{-i 2\\pi k' 0} + (\\sum^{L-1}_{n=0} x(n+1L) e^{-i 2 \\pi k' n/L}) e^{-i 2\\pi k' 1} + ... \\\\\n",
    "\\end{aligned}\n",
    "$$\n",
    "\n",
    "Since we have defined $k'$ to be an integer via our assumptions, the factors $e^{-i 2\\pi k' 0}, e^{-i 2\\pi k' 1}, ...$ are all equal to 1 and drop out. Hence we see clearly that the sum of FFTs can be described succinctly as\n",
    "\n",
    "$$\n",
    "X(k') = \\sum_l \\sum^{L-1}_{n=0} x(n+lL) e^{-i 2 \\pi k' n / L}\n",
    "$$\n",
    "\n",
    "Now, in a bursty signal, depending on the length $L$ chosen, many of these windows may be full of 0s, and may be ignored in a given computation. Evidently, in a fully periodic burst, with a length $L$ chosen to match the signal's burst length, then only the bursts with the signal itself would need to be included.\n",
    "\n",
    "However, it is likely that burst's short length and associated bin resolution may not be sufficient for the desired use case. In this scenario, one would likely select a larger window and compute only those windows which contain samples from a burst. Some extra thought here offers yet another layer of optimization. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "faced-poker",
   "metadata": {},
   "source": [
    "# Old Theory\n",
    "\n",
    "In practice, one would have pre-processed the bursts to at least know the samples at which each burst starts; that is, we can define the samples $n_0, n_1 ...$ as the starting samples for each burst. Similarly, we can define the length of the burst as $L$ (this can be rounded up to the nearest sample if $t_L$ sits in a subsample range.\n",
    "\n",
    "We would now perform the FFTs over each burst in the following way:\n",
    "\n",
    "$$X_i (k) = \\sum^{L-1}_{l} x(n_i + l) e^{-i 2 \\pi k l / L}, k = 0, 1, .. L-1 $$\n",
    "\n",
    "Now, clearly the FFT resolution for the short burst is far worse i.e. the bin widths are larger due to taking a smaller window. We will get to this. For now, suppose the original (large) window length is an integer multiple of the shorter window length i.e. $N = \\alpha L$.\n",
    "\n",
    "Then, every $\\alpha$'th bin in the original (large) window corresponds to a bin in the shorter window. We will use this to demonstrate the corrections required.\n",
    "\n",
    "Consider the first pair of bins which correspond to each other: this is the integer $\\alpha$ in the original (large) window and the integer $1$ in the shorter window. There is no change in the 0'th terms (which do pair up with each other) as they are simply summations over all samples, and are equivalent without any corrections.\n",
    "\n",
    "Remembering that $N = \\alpha L$, we have\n",
    "\n",
    "$$X(\\alpha) = \\sum^{N-1}_{n} x(n) e^{-i 2 \\pi \\alpha n / N}, k = 0, 1, ... N-1 $$\n",
    "$$X_i (1) = \\sum^{L-1}_{l} x(n_i + l) e^{-i 2 \\pi \\alpha l / N}, k = 0, 1, .. L-1 $$\n",
    "\n",
    "Consider the term at the start of the burst - the sample at $x(n_i + l)$. The contribution of this term to the original window is given by \n",
    "\n",
    "$$F_o = x(n_i + l) e^{-i 2 \\pi \\alpha (n_i + l) / N}$$\n",
    "\n",
    "whereas the term from the short window is given by\n",
    "\n",
    "$$F_s = x(n_i + l) e^{-i 2 \\pi \\alpha (l) / N}$$\n",
    "\n",
    "which clearly shows that \n",
    "\n",
    "$$ F_0 = F_s e^{-i 2 \\pi \\alpha (n_i) / N} $$\n",
    "\n",
    "This shows that the coefficient needed to ensure coherency between the short and long windows is the term $e^{-i 2 \\pi \\alpha (n_i) / N}$. It follows that the coefficients required for the other frequency pairs $(2\\alpha, 2), (3\\alpha, 3) ... $ are\n",
    "\n",
    "$$ e^{-i 2 \\pi 2 \\alpha (n_i) / N} $$\n",
    "$$ e^{-i 2 \\pi 3 \\alpha (n_i) / N} $$\n",
    "\n",
    "and so on.\n",
    "\n",
    "It should also be noted that these terms do not depend on $l$ whatsoever. Hence the following relations hold:\n",
    "\n",
    "$$ X(\\alpha) = ... + X_i(1) e^{-i 2 \\pi \\alpha (n_i) / N} + ... $$\n",
    "$$ X(2\\alpha) = ... + X_i(1) e^{-i 2 \\pi 2\\alpha (n_i) / N} + ... $$\n",
    "$$.$$\n",
    "$$.$$\n",
    "$$.$$\n",
    "\n",
    "In other words, to ensure coherency for a particular bin, we need only take the individual short window FFTs - the terms $X_i$ - with a complex exponential coefficient that depends on the starting sample. Looking at it through this vectorized format may be more intuitive from a programming perspective:\n",
    "\n",
    "$$\\begin{bmatrix}\n",
    "X(0) \\\\\n",
    "X(\\alpha) \\\\\n",
    "X(2 \\alpha) \\\\\n",
    "X(3 \\alpha)\\\\\n",
    ". \\\\\n",
    ". \\\\\n",
    ". \\\\\n",
    "\\end{bmatrix} = ... + \\begin{bmatrix}\n",
    "e^{-i 2 \\pi 0\\alpha (n_i) / N} \\\\\n",
    "e^{-i 2 \\pi 1\\alpha (n_i) / N} \\\\\n",
    "e^{-i 2 \\pi 2\\alpha (n_i) / N} \\\\\n",
    "e^{-i 2 \\pi 3\\alpha (n_i) / N}\\\\\n",
    ". \\\\\n",
    ". \\\\\n",
    ". \\\\\n",
    "\\end{bmatrix} \\odot \\begin{bmatrix}\n",
    "X_i(0) \\\\\n",
    "X_i(1) \\\\\n",
    "X_i(2) \\\\\n",
    "X_i(3)\\\\\n",
    ". \\\\\n",
    ". \\\\\n",
    ". \\\\\n",
    "\\end{bmatrix}\n",
    " + ... $$\n",
    "\n",
    "The $\\odot$ here represents the Hadamard product (element-wise multiplication). We see that given the FFT output of the i'th burst starting at sample $n_i$ - that is, the vector $\\begin{bmatrix}\n",
    "X_i(0) & X_i(1) & X_i(2) & X_i(3) & ...\n",
    "\\end{bmatrix}^T$ - we only need to multiply in another equal length vector with coefficients that are equal to $\\begin{bmatrix}\n",
    "e^{-i 2 \\pi 0\\alpha (n_i) / N} &\n",
    "e^{-i 2 \\pi 1\\alpha (n_i) / N} &\n",
    "e^{-i 2 \\pi 2\\alpha (n_i) / N} &\n",
    "e^{-i 2 \\pi 3\\alpha (n_i) / N} & ...\n",
    "\\end{bmatrix}^T$. Repeating this for every individual burst, one obtains coherent values for the FFT bins with respect to the original longer window.\n",
    "\n",
    "The computational advantage for this is immediately apparent for a periodic burst. For example, if a burst has a length of 0.1s and occurs every 1s (10% occupancy in time), and the original large window captures 10 bursts, then the large window requires 10s of samples (yes, this adds the final unnecessary 0s behind the last burst, but for many bursts this will be insignificant). This results in a rough computational complexity of around $O(10 \\log 10)$. On the other hand, processing 10 small FFTs will result in a complexity of around $O(10 * 0.1 \\log (0.1)) = O(\\log(0.1))$. This is clearly an immense decrease in complexity with the caveat that the resolution has also similarly decreased.\n",
    "\n",
    "## Increasing the Short Window Resolution\n",
    "\n",
    "\n",
    "\n",
    "# Generation of Coefficient Vectors (IPP)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "miniature-september",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
